# -*- coding: utf-8 -*-
import os
import time
import logging
import pandas as pd
import urllib.request
from PIL import Image
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from PIL import Image, ImageOps

# ---------------- CONFIG ----------------
output_path = r"C:\Users\tanapat\Downloads\base_feature_images_all_pages_BAK_Leather.xlsx"
base_folder = r"D:\HIC Feture\test"
origin_folder = os.path.join(base_folder, "origin")
crop_folder = os.path.join(base_folder, "crop")

GOOGLE_EMAIL = "tanapat@chanintr.com"
GOOGLE_PASSWORD = "Qwerty12345$$"

crop_top_bottom = 75
crop_left_right = 75

os.makedirs(origin_folder, exist_ok=True)
os.makedirs(crop_folder, exist_ok=True)

# ---------------- Chrome Options ----------------
chrome_options = Options()
chrome_options.add_argument("--start-maximized")
chrome_options.add_argument("--disable-notifications")
driver = webdriver.Chrome(options=chrome_options)
wait = WebDriverWait(driver, 20)

# ---------------- Logging ----------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# ---------------- STEP 1: Google Login ----------------
try:
    driver.get("https://accounts.google.com/signin/v2/identifier")

    email_input = wait.until(EC.element_to_be_clickable((By.XPATH, "//input[@type='email']")))
    email_input.clear()
    email_input.send_keys(GOOGLE_EMAIL)
    driver.find_element(By.ID, "identifierNext").click()

    password_input = wait.until(EC.element_to_be_clickable((By.XPATH, "//input[@type='password']")))
    password_input.clear()
    password_input.send_keys(GOOGLE_PASSWORD)
    driver.find_element(By.ID, "passwordNext").click()

    logging.info("‚úÖ ‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¥‡∏ô Google ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    time.sleep(5)
except TimeoutException:
    logging.error("‚ùå ‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏¥‡∏ô Google ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    driver.quit()
    exit()

# ---------------- STEP 2: Base Login ----------------
try:
    driver.get("https://base.chanintr.com/login")
    google_btn = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'Sign in with Google')]")))
    google_btn.click()
    logging.info("‚úÖ ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° Sign in with Google ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    time.sleep(10)
except TimeoutException:
    logging.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏õ‡∏∏‡πà‡∏° Sign in with Google")
    driver.quit()
    exit()

# ---------------- STEP 3: ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤ features ----------------
target_url = "https://base.chanintr.com/brand/10/features?featureTypeId=6&isUnassigned=false&isSearch=false"
driver.get(target_url)
logging.info("üåê ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤ features ‡πÅ‡∏•‡πâ‡∏ß ‡∏£‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤...")

# ---------------- STEP 4: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤ ----------------
def extract_page_data():
    data_page = []
    seen_names = set()
    try:
        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "ul > li > div.cell-thumbnail img")))
        time.sleep(1.5)
        items = driver.find_elements(By.CSS_SELECTOR, "ul > li")

        for li in items:
            try:
                img_el = li.find_element(By.CSS_SELECTOR, "div.cell-thumbnail img")
                img_url = img_el.get_attribute("src")

                name_el = li.find_element(By.CSS_SELECTOR, "div:nth-child(3) h3")
                name_text = name_el.text.strip()

                row_data = {"name": name_text, "image_url": img_url}

                # ‡∏ñ‡πâ‡∏≤ name ‡∏ã‡πâ‡∏≥ -> ‡∏î‡∏∂‡∏á code ‡πÄ‡∏û‡∏¥‡πà‡∏°
                if name_text in seen_names:
                    try:
                        code_el = li.find_element(By.CSS_SELECTOR, "div:nth-child(3) p")
                        row_data["code"] = code_el.text.strip()
                    except NoSuchElementException:
                        row_data["code"] = ""
                else:
                    seen_names.add(name_text)

                data_page.append(row_data)
            except Exception:
                continue

        logging.info(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ {len(data_page)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    except TimeoutException:
        logging.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ")
    return data_page

# ---------------- STEP 5: ‡∏ß‡∏ô‡∏ó‡∏∏‡∏Å‡∏´‡∏ô‡πâ‡∏≤ ----------------
all_data = []
page = 1
while True:
    logging.info(f"üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡πâ‡∏≤ {page} ...")
    all_data.extend(extract_page_data())

    # ‡∏´‡∏≤ next page
    try:
        next_btn = None
        buttons = driver.find_elements(By.CSS_SELECTOR, "ul.pagination li button")
        for btn in buttons:
            if btn.find_elements(By.CSS_SELECTOR, "svg[data-icon='angle-right']"):
                next_btn = btn
                break

        if next_btn and next_btn.is_enabled():
            driver.execute_script("arguments[0].scrollIntoView(true);", next_btn)
            time.sleep(1)
            next_btn.click()
            logging.info(f"‚û°Ô∏è ‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡∏´‡∏ô‡πâ‡∏≤ {page + 1})")
            page += 1
            time.sleep(1)
        else:
            logging.info("‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß ‚Äî ‡∏´‡∏¢‡∏∏‡∏î‡∏•‡∏π‡∏õ")
            break
    except Exception:
        logging.info("‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏∏‡πà‡∏° Next ‚Äî ‡∏´‡∏¢‡∏∏‡∏î‡∏•‡∏π‡∏õ")
        break

driver.quit()

# ---------------- STEP 6: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Excel ----------------
pd.DataFrame(all_data).to_excel(output_path, index=False)
logging.info(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏•‡∏á‡πÑ‡∏ü‡∏•‡πå: {output_path}")

# ---------------- STEP 7: ‡πÇ‡∏´‡∏•‡∏î‡∏†‡∏≤‡∏û origin ----------------
df = pd.read_excel(output_path)

if 'image_url' not in df.columns or 'name' not in df.columns:
    print("‚ùå Columns 'image_url' or 'name' not found.")
else:
    for idx, row in df.dropna(subset=['image_url', 'name']).iterrows():
        try:
            url = row['image_url']
            base_name = str(row['code']).strip() if 'code' in row and pd.notna(row['code']) else str(row['name']).strip()
            base_name = base_name.replace('/', '_').replace('\\', '_')
            filename = f"{base_name}.jpg"
            origin_path = os.path.join(origin_folder, filename)
            crop_path = os.path.join(crop_folder, filename)

            if os.path.exists(origin_path):
                print(f"‚è© Skip existing: {filename}")
                continue

            print(f"Downloading {idx+1}: {url} -> {filename}")
            urllib.request.urlretrieve(url, origin_path)
            time.sleep(0.2)

            # ‡∏Å‡πá‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡πÑ‡∏õ crop
            with Image.open(origin_path) as img:
                img.save(crop_path, format='JPEG')

        except Exception as e:
            print(f"‚ùå Failed to download {url}: {e}")

print("‚úÖ Finished downloading all original images")

# ---------------- STEP 8: Crop 75px ‡∏ö‡∏ô/‡∏•‡πà‡∏≤‡∏á/‡∏ã‡πâ‡∏≤‡∏¢/‡∏Ç‡∏ß‡∏≤ ----------------
for file in os.listdir(crop_folder):
    if file.lower().endswith(".jpg"):
        filepath = os.path.join(crop_folder, file)
        try:
            with Image.open(filepath) as img:
                width, height = img.size
                if height > crop_top_bottom * 2 and width > crop_left_right * 2:
                    img_cropped = img.crop((
                        crop_left_right,
                        crop_top_bottom,
                        width - crop_left_right,
                        height - crop_top_bottom
                    ))
                    img_cropped.save(filepath, format='JPEG')
        except Exception as e:
            print(f"‚ùå Failed to crop {file}: {e}")

print("‚úÖ Finished cropping all images in 'crop'")